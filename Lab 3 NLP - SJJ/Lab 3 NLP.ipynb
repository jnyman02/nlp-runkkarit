{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1631759b-e72d-471c-b803-550086976831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import similar libraries to the ones included in Python script file 3\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.corpus import genesis\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# download nltk wordnet\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fe35b4b7-6017-48be-a843-40478a5455d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a function to calculate similarity of two STRINGS AND print it out\n",
    "# This will be useful since we will need to calculate many similarities\n",
    "def wu_sim_string(string1, string2):\n",
    "    # Get sysnets of given strings 1 and 2\n",
    "    sys1list = wn.synsets(string1)\n",
    "    sys2list = wn.synsets(string2)\n",
    "\n",
    "    # Run a for statements for each sysnet\n",
    "    for sys1 in sys1list:\n",
    "        for sys2 in sys2list:\n",
    "            print(f\"Similarity between {sys1} and {sys2}: {sys1.wup_similarity(sys2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dd81bce0-36bd-4dd9-ad27-e56b7fce5bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# However, it may be more useful to calculate the wup similarity\n",
    "# if we already have the synset\n",
    "def wu_sim_syn(syn1, syn2):\n",
    "    similarity = syn1.wup_similarity(syn2)\n",
    "    #print(f\"Similarity between {syn1} and {syn2}: {similarity}\")\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9b58d100-95f9-4fe0-adb5-656f1739777c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we make a function to return S1, S2, and S3 for any given 2 strings\n",
    "def calculate_similarities(string1, string2):\n",
    "    sys1list = wn.synsets(string1)\n",
    "    sys2list = wn.synsets(string2)\n",
    "    # Create emmpty similarity variables\n",
    "    S1 = 0\n",
    "    S2 = 2\n",
    "    S3 = 0\n",
    "    number_of_syn = 0\n",
    "    tmp_sim = 0\n",
    "    for sys1 in sys1list:\n",
    "        for sys2 in sys2list:\n",
    "            tmp_sim = wu_sim_syn(sys1, sys2)\n",
    "            # Update needed values, no need for if statement\n",
    "            #https://www.geeksforgeeks.org/maximum-of-two-numbers-in-python/\n",
    "            S1 = max(S1, tmp_sim)\n",
    "            S2 = min(S2, tmp_sim)\n",
    "        S3 += tmp_sim\n",
    "        number_of_syn += 1\n",
    "    # Now calculate average for S3 and return\n",
    "    S3 = S3 / number_of_syn if number_of_syn > 0 else 0\n",
    "    print(\"\\nS1: \",S1)\n",
    "    print(\"\\nS2: \",S2)\n",
    "    print(\"\\nS3: \",S3)\n",
    "    return S1, S2, S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "98726d37-e4df-47f8-9de9-f7fa12120035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same same but for the first hypernym of the given words\n",
    "def calculate_hypernym_similarities(string1, string2):\n",
    "    # We need to find the firsy hypernym of the given string\n",
    "    # wn.synsets(\"dog\")[0].hypernyms()[0]\n",
    "    sys1list = wn.synsets(string1)\n",
    "    sys2list = wn.synsets(string2)\n",
    "    # Create emmpty similarity variables\n",
    "    S1 = 0\n",
    "    S2 = 2\n",
    "    S3 = 0\n",
    "    number_of_syn = 0\n",
    "    for sys1 in sys1list:\n",
    "        for sys2 in sys2list:\n",
    "            tmp_sim = wu_sim_syn(sys1.hypernyms()[0], sys2.hypernyms()[0])\n",
    "            # Update needed values, no need for if statement\n",
    "            #https://www.geeksforgeeks.org/maximum-of-two-numbers-in-python/\n",
    "            S1 = max(S1, tmp_sim)\n",
    "            S2 = min(S2, tmp_sim)\n",
    "        S3 += tmp_sim\n",
    "        number_of_syn += 1\n",
    "    # Now calculate average for S3 and return\n",
    "    S3 = S3 / number_of_syn if number_of_syn > 0 else 0\n",
    "    print(\"\\nS1: \",S1)\n",
    "    print(\"\\nS2: \",S2)\n",
    "    print(\"\\nS3: \",S3)\n",
    "    return S1, S2, S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d1891238-9a62-4bf5-8e1b-4b452727e286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same same but for the first hypernym of the given words\n",
    "def calculate_hypernym_similarities(string1, string2):\n",
    "    # We need to find the firsy hypernym of the given string\n",
    "    # wn.synsets(\"dog\")[0].hypernyms()[0]\n",
    "    sys1list = wn.synsets(string1)\n",
    "    sys2list = wn.synsets(string2)\n",
    "    # Create emmpty similarity variables\n",
    "    S1 = 0\n",
    "    S2 = 2\n",
    "    S3 = 0\n",
    "    number_of_syn = 0\n",
    "    for sys1 in sys1list:\n",
    "        for sys2 in sys2list:\n",
    "            tmp_sim = wu_sim_syn(sys1.hypernyms()[0], sys2.hypernyms()[0])\n",
    "            # Update needed values, no need for if statement\n",
    "            #https://www.geeksforgeeks.org/maximum-of-two-numbers-in-python/\n",
    "            S1 = max(S1, tmp_sim)\n",
    "            S2 = min(S2, tmp_sim)\n",
    "        S3 += tmp_sim\n",
    "        number_of_syn += 1\n",
    "    # Now calculate average for S3 and return\n",
    "    S3 = S3 / number_of_syn if number_of_syn > 0 else 0\n",
    "    print(\"\\nS1: \",S1)\n",
    "    print(\"\\nS2: \",S2)\n",
    "    print(\"\\nS3: \",S3)\n",
    "    return S1, S2, S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c592ee2d-9d19-4198-8826-6c9750098603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same same but for the all hyponem of the given words\n",
    "def calculate_hyponym_similarities(string1, string2):\n",
    "    # We need to find the hyponym of the given string\n",
    "    sys1list = wn.synsets(string1)\n",
    "    sys2list = wn.synsets(string2)\n",
    "    # Create emmpty similarity variables\n",
    "    S1 = 0\n",
    "    S2 = 2\n",
    "    S3 = 0\n",
    "    number_of_syn = 0\n",
    "    for sys1 in sys1list:\n",
    "        for sys2 in sys2list:\n",
    "            # Now iterate for the hyponyms of given synset\n",
    "            for hypo1 in sys1.hyponyms():\n",
    "                for hypo2 in sys2.hyponyms():\n",
    "                    \n",
    "                    tmp_sim = wu_sim_syn(hypo1, hypo2)\n",
    "                    # Update needed values, no need for if statement\n",
    "                    #https://www.geeksforgeeks.org/maximum-of-two-numbers-in-python/\n",
    "                    S1 = max(S1, tmp_sim)\n",
    "                    S2 = min(S2, tmp_sim)\n",
    "                S3 += tmp_sim\n",
    "                number_of_syn += 1\n",
    "    # Now calculate average for S3 and return\n",
    "    S3 = S3 / number_of_syn\n",
    "    print(\"\\nS1: \",S1)\n",
    "    print(\"\\nS2: \",S2)\n",
    "    print(\"\\nS3: \",S3)\n",
    "    return S1, S2, S3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f647079",
   "metadata": {},
   "source": [
    "## Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8210a2-0f02-47d7-8d79-21cd91fe335a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dowload needed corpuses\n",
    "nltk.download('brown')\n",
    "nltk.download('wordnet_ic')\n",
    "\n",
    "from nltk.corpus import wordnet_ic\n",
    "\n",
    "brown_ic = wordnet_ic.ic('ic-brown.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e67fbfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define a function to calculate the Jiang-Conrath similarity of two synsets\n",
    "def get_jcn_similarity(synset1, synset2):\n",
    "    # Initialize variables\n",
    "    S1 = 0\n",
    "    S2 = float('inf')\n",
    "    total = 0\n",
    "    number_of_syn = 0\n",
    "    \n",
    "    # Iterate through all synsets of both strings and calculate the similarity\n",
    "    for sys1 in synset1:\n",
    "        for sys2 in synset2:\n",
    "            tmp_sim = sys1.jcn_similarity(sys2, brown_ic)\n",
    "            S1 = max(S1, tmp_sim)\n",
    "            S2 = min(S2, tmp_sim)\n",
    "            total += tmp_sim\n",
    "            number_of_syn += 1\n",
    "    \n",
    "    # Calculate the average similarity and return all three values\n",
    "    S3 = total / number_of_syn if number_of_syn > 0 else 0\n",
    "    return S1, S2, S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb9392b-03ee-4786-8044-0aadaa270748",
   "metadata": {},
   "outputs": [],
   "source": [
    "string1 = \"car\"\n",
    "string2 = \"bus\"\n",
    "S1, S2, S3 = calculate_similarities(string1, string2)\n",
    "hyper1, hyper2, hyper3 = calculate_hypernym_similarities(string1, string2)\n",
    "hypo1, hypo2, hypo3 = calculate_hyponym_similarities(string1, string2)\n",
    "\n",
    "eval1, eval2, eval3 = max(S1, hyper1, hypo1), max(S2, hyper2, hypo2), max(S3, hyper3, hypo3)\n",
    "print(\"\\neval1: \",eval1)\n",
    "print(\"\\neval2: \",eval2)\n",
    "print(\"\\neval3: \",eval3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2765b064",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TASK 4\n",
    "\n",
    "# Filter synsets to only include those with the same part of speech\n",
    "synsets1 = [syn for syn in wn.synsets(string1) if syn.pos() == 'n']\n",
    "synsets2 = [syn for syn in wn.synsets(string2) if syn.pos() == 'n']\n",
    "\n",
    "S1, S2, S3 = get_jcn_similarity(synsets1, synsets2)\n",
    "print(\"\\nJiang-Conrath Similarity\")\n",
    "print(\"\\nS1: \",S1)\n",
    "print(\"\\nS2: \",S2)\n",
    "print(\"\\nS3: \",S3)\n",
    "\n",
    "S1_hyper, S2_hyper, S3_hyper = get_jcn_similarity(synsets1[0].hypernyms(), synsets2[0].hypernyms())\n",
    "print(\"\\nJiang-Conrath Similarity with hypernyms\")\n",
    "print(\"\\nS1: \",S1_hyper)\n",
    "print(\"\\nS2: \",S2_hyper)\n",
    "print(\"\\nS3: \",S3_hyper)\n",
    "\n",
    "S1_hypo, S2_hypo, S3_hypo = get_jcn_similarity(synsets1[0].hyponyms(), synsets2[0].hyponyms())\n",
    "print(\"\\nJiang-Conrath Similarity with hyponyms\")\n",
    "print(\"\\nS1: \",S1_hypo)\n",
    "print(\"\\nS2: \",S2_hypo)\n",
    "print(\"\\nS3: \",S3_hypo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c46b727",
   "metadata": {},
   "source": [
    "## Task 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120d69ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "901db55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sentence, sropword_removal=False, stemming=False):\n",
    "    tokens = word_tokenize(sentence.lower())\n",
    "    if sropword_removal:\n",
    "        tokens = [word for word in tokens if word not in stop_words]\n",
    "    if stemming:\n",
    "        stemmer = SnowballStemmer(\"english\")\n",
    "        tokens = [stemmer.stem(word) for word in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1ec02339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_similarity(tokens1, tokens2):\n",
    "    total_similarity = 0\n",
    "    count = 0\n",
    "    for token1 in tokens1:\n",
    "        max_similarity = 0\n",
    "        for token2 in tokens2:\n",
    "            S1, S2, S3 = calculate_similarities(token1, token2)\n",
    "            if S1 > max_similarity:\n",
    "                max_similarity = S1\n",
    "        total_similarity += max_similarity\n",
    "        count += 1\n",
    "    return total_similarity / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e87d85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "T1 = \"Students feel unhappy today about the class today.\"\n",
    "T2 = \"Several students study hard at classes in recent days.\"\n",
    "\n",
    "tokens1 = preprocess(T1)\n",
    "tokens2 = preprocess(T2)\n",
    "\n",
    "print(\"\\nSentence Similarity without preprocessing: \", get_sentence_similarity(tokens1, tokens2))\n",
    "\n",
    "tokens1 = preprocess(T1, sropword_removal=True)\n",
    "tokens2 = preprocess(T2, sropword_removal=True)\n",
    "\n",
    "print(\"\\nSentence Similarity with stopword removal: \", get_sentence_similarity(tokens1, tokens2))\n",
    "\n",
    "tokens1 = preprocess(T1, sropword_removal=True, stemming=True)\n",
    "tokens2 = preprocess(T2, sropword_removal=True, stemming=True)\n",
    "\n",
    "print(\"\\nSentence Similarity with stopword removal and stemming: \", get_sentence_similarity(tokens1, tokens2))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
